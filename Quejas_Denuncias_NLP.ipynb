{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf50b6b0-e941-416e-9ea4-4fe3dec2db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Restructuración del código de clasificacion SIPRE (QUEJAS-DENUNICAS-UNIDAD)\n",
    "### Ladino Álvarez Ricardo Arturo\n",
    "\n",
    "### Librerias\n",
    "#> Base\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from io import StringIO\n",
    "\n",
    "#> NLP\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "stopword = set(stopwords.words('spanish'))\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "#> Machine Learning\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,mean_squared_error\n",
    "\n",
    "#> Desbalance de clase\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "\n",
    "#> Errores\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1084fb-e309-4204-b447-d944910cfb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entradas = 'C:/Users/LAAR8976/Ladino_ALL/CECTI/CLASIFICADOR_DENUNCIAS_QUEJAS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00d355-c306-4ccc-abf9-6291304e7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quejas = pd.read_excel(Entradas + 'Quejas.xlsx')\n",
    "Denucias = pd.read_excel(Entradas + 'Denucias.xlsx')\n",
    "print(Quejas.shape)\n",
    "print(Denucias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7958a-d39d-4882-ac60-aea47fe9f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quejas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a42c9-a166-4220-bcd5-4cc3e9e73f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Denucias.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46b8c3-366c-4290-a005-f3bfa09127fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar que ambas bases tienen las mismas columnas\n",
    "if list(Quejas.columns) == list(Denucias.columns):\n",
    "    print(\"Ambas bases tienen los mismos nombres de columnas. Puedes concatenarlas.\")\n",
    "    # Concatenar si la validación es exitosa\n",
    "    datos_concatenados = pd.concat([Quejas, Denucias], ignore_index=True)\n",
    "    print(\"Concatenación exitosa.\")\n",
    "else:\n",
    "    print(\"Las columnas no coinciden entre las bases. Revisa los nombres de las columnas.\")\n",
    "    print(\"Columnas en Quejas:\", Quejas.columns.tolist())\n",
    "    print(\"Columnas en Denuncias:\", Denucias.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d00e00-0f4b-499f-9410-498439e91158",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_concatenados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06ff7b-9251-4c5f-b8e5-d2fdfc97b692",
   "metadata": {},
   "source": [
    "### Sección con Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554e018-38b8-45e5-9ecb-573c3505e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(datos_concatenados, open(\"datos_concatenados.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b63d9ede-528c-449b-8e68-afa0a49ae17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### importar datos concatenados:\n",
    "\n",
    "datos_concatenados = pd.read_pickle('datos_concatenados.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67c282c2-a3d9-4540-bfff-b42dcd2fad04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tipo asunto\n",
       "Denuncia    106203\n",
       "Queja        40118\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Remuestreo = datos_concatenados[['Consecutivo', 'Folio SIPRE', 'Descripción de los Hechos', \n",
    "                      'Tipo asunto', 'Clasificación', 'AG Asignada', 'UA Asignada']]\n",
    "Remuestreo['Tipo asunto'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6687c-13cb-417e-92e0-39ca39ae3ba6",
   "metadata": {},
   "source": [
    "### Representatividad de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5edd7a4-9b21-4ded-a881-50a883bb920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73161, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tipo asunto\n",
       "Denuncia    53102\n",
       "Queja       20059\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Función de representatividad\n",
    "\n",
    "def Repre_clase(Clase_Size):\n",
    "    if Clase_Size < 500:\n",
    "        return 1.0  # 100%\n",
    "    elif 500 <= Clase_Size <= 5000:\n",
    "        return 0.8  # 80%\n",
    "    else:\n",
    "        return 0.5  # 50%\n",
    "        \n",
    "Muestras = Remuestreo['Tipo asunto'].value_counts().apply(Repre_clase)\n",
    "\n",
    "# Aplicar el muestreo por clase\n",
    "Datos_Muestra = Remuestreo.groupby('Tipo asunto').apply(lambda x: x.sample(frac = Muestras[x.name],\n",
    "                                                                            random_state = 42)).reset_index(drop = True)\n",
    "\n",
    "print(Datos_Muestra.shape)\n",
    "Datos_Muestra['Tipo asunto'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7edeab7-c9f5-409f-9130-7fbb62b0c11a",
   "metadata": {},
   "source": [
    "### Catálogos de interpretación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e0dbe2a-89e7-4a7a-9d6c-3f4436caa95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consecutivo</th>\n",
       "      <th>Folio SIPRE</th>\n",
       "      <th>Descripción de los Hechos</th>\n",
       "      <th>Tipo asunto</th>\n",
       "      <th>Clasificación</th>\n",
       "      <th>AG Asignada</th>\n",
       "      <th>UA Asignada</th>\n",
       "      <th>Tipo_asunto</th>\n",
       "      <th>UA_Asignada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>643547</td>\n",
       "      <td>72712</td>\n",
       "      <td>Descripción de los hechos: Recibo de nomina no...</td>\n",
       "      <td>Denuncia</td>\n",
       "      <td>Comprobantes Fiscales</td>\n",
       "      <td>AGAFF</td>\n",
       "      <td>AGAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>671094</td>\n",
       "      <td>100259</td>\n",
       "      <td>Descripción de los hechos: Se realizó un servi...</td>\n",
       "      <td>Denuncia</td>\n",
       "      <td>Comprobantes Fiscales</td>\n",
       "      <td>AGAFF</td>\n",
       "      <td>AGAFF</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Consecutivo  Folio SIPRE  \\\n",
       "0       643547        72712   \n",
       "1       671094       100259   \n",
       "\n",
       "                           Descripción de los Hechos Tipo asunto  \\\n",
       "0  Descripción de los hechos: Recibo de nomina no...    Denuncia   \n",
       "1  Descripción de los hechos: Se realizó un servi...    Denuncia   \n",
       "\n",
       "           Clasificación AG Asignada UA Asignada  Tipo_asunto  UA_Asignada  \n",
       "0  Comprobantes Fiscales       AGAFF       AGAFF            0           11  \n",
       "1  Comprobantes Fiscales       AGAFF       AGAFF            0           11  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clases = preprocessing.LabelEncoder()\n",
    "Datos_Muestra['Tipo_asunto'] = Clases.fit_transform(Datos_Muestra['Tipo asunto'])\n",
    "Datos_Muestra['UA_Asignada'] = Clases.fit_transform(Datos_Muestra['UA Asignada'])\n",
    "Datos_Muestra.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4817c89b-680d-4634-8505-d885c8370901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tipo_asunto = pd.DataFrame(set(zip(Datos_Muestra['Tipo asunto'],\n",
    "                                      Datos_Muestra['Tipo_asunto'])),\n",
    "                              columns =['Queja_Denuncia', 'Code']).sort_values(by='Code', ascending = True)\n",
    "\n",
    "UA_Asignada = pd.DataFrame(set(zip(Datos_Muestra['UA Asignada'],\n",
    "                                      Datos_Muestra['UA_Asignada'])),\n",
    "                              columns =['UA_Asignada', 'Code']).sort_values(by='Code', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016546a-e690-4912-b398-6eba6b4c3223",
   "metadata": {},
   "source": [
    "### Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "def3303b-ff11-4641-a80e-abaa04126210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Función de Normalización del texto\n",
    "\n",
    "### Limpieza de texto\n",
    "def limpiar_texto(texto):\n",
    "    # > 00 - StopWords\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    # > 01 - Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    # > 02 - Eliminar signos de puntuación y números\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    texto = re.sub(r'\\d+', '', texto)\n",
    "    \n",
    "    # > 03 - Eliminar acentos y caracteres especiales\n",
    "    #texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # > 04 Eliminar stopwords\n",
    "    texto = ' '.join([palabra for palabra in texto.split() if palabra not in stop_words])\n",
    "    \n",
    "    # > 05 Eliminar palabras cortas\n",
    "    texto = ' '.join([palabra for palabra in texto.split() if len(palabra) > 2])\n",
    "\n",
    "    # > 06 Corrección ortográfica\n",
    "    #texto = ' '.join([spell.correction(palabra) for palabra in texto.split()])\n",
    "\n",
    "    # > 07 Lematización\n",
    "    #texto = ' '.join([token.lemma_ for token in nlp(texto)])\n",
    "\n",
    "    return (texto)\n",
    "\n",
    "### Limpieza de múltiples columnas\n",
    "def limpiar_columnas(df, columnas):\n",
    "    for columna in columnas:\n",
    "        df[columna] = df[columna].astype(str).fillna('')  # Convertir a string y manejar NaNs\n",
    "        df[columna] = df[columna].apply(limpiar_texto)    # Aplicar la función de limpieza completa\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a64c07d0-8d28-4ff0-aa32-91cfaf7954ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos_Muestra_N = Datos_Muestra.copy()\n",
    "Columnas_Limpia = ['Descripción de los Hechos'] \n",
    "Datos_Muestra_N = limpiar_columnas(Datos_Muestra_N, Columnas_Limpia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75933ed3-759d-4735-8919-649e4414177b",
   "metadata": {},
   "source": [
    "### Prueba y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0b714e7-e303-4493-9096-4d0132f1c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Datos_Muestra_N['Descripción de los Hechos'],\n",
    "                                                    Datos_Muestra_N['Tipo_asunto'],\n",
    "                                                    stratify = Datos_Muestra_N['Tipo_asunto'],\n",
    "                                                    test_size = 0.60,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a283544-ed29-4a52-874f-c887a5ed90cf",
   "metadata": {},
   "source": [
    "### Vector de aprendizaje + Bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fef59f84-188f-45e5-853d-06de81935c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = TfidfVectorizer(strip_accents = 'unicode', \n",
    "                        analyzer = 'word',\n",
    "                        max_features = 10000,\n",
    "                        norm='l2',\n",
    "                        encoding = 'latin-1',\n",
    "                        token_pattern = r'\\w{1,}',\n",
    "                        ngram_range = (1, 2), \n",
    "                        use_idf = True,\n",
    "                        smooth_idf = True, \n",
    "                        sublinear_tf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "673bf6eb-fa18-495e-bb93-f8b614a4cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDFT = TFIDF.fit(list(X_train) + list(X_test))\n",
    "X_train_N =  TDFT.transform(X_train) \n",
    "X_test_N = TFIDF.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60fc144b-c70b-4612-b100-4ded66ceb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(TDFT, open(\"Palabras_Tipo_Asunto.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ba5ef86-163b-47c3-b4ef-10fc891602e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([21241,  8023]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7680dc96-8eca-4d67-9986-161b5fc8e21f",
   "metadata": {},
   "source": [
    "# Etiquetas en un array `y_train`\n",
    "class_counts = Counter(y_train)\n",
    "minority_class = min(class_counts, key = class_counts.get)\n",
    "majority_class = max(class_counts, key = class_counts.get)\n",
    "\n",
    "# Definir el número de muestras necesarias\n",
    "sampling_strategy = {minority_class: class_counts[majority_class]}\n",
    "\n",
    "# Instanciar SMOTEN con el `sampling_strategy` calculado dinámicamente\n",
    "smoten = SMOTEN(sampling_strategy = sampling_strategy,\n",
    "                random_state = 42, \n",
    "                n_jobs = -1)\n",
    "\n",
    "# Aplicar SMOTEN al conjunto de datos\n",
    "X_resampled, y_resampled = smoten.fit_resample(X_train_N, y_train)\n",
    "\n",
    "# Verificar la nueva distribución\n",
    "#print(\"Distribución después de SMOTEN:\", Counter(y_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "985b8e46-7ce6-43f6-bb4a-b830ce7bd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_N, open(\"X_train_N.pkl\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"y_train.pkl\", \"wb\"))\n",
    "pickle.dump(X_test_N, open(\"X_test_N.pkl\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"y_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db91cb77-372a-4337-aecd-e530d860d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ================================= ================================= =============================== ###\n",
    "### ========================================= QUEJAS & DENUNCIAS ====================================== ###\n",
    "### ============================== FUNCIÓN DE APRENDIZAJE MAQUINA ===================================== ###\n",
    "\n",
    "def Aprendizaje_Queja_Denuncia(X_train, X_test, y_train, y_test, Model):\n",
    "    ''' Función de modelo de aprendizaje, que ejecuta lo siguiente:\n",
    "        A) Se evaluan diferentes modelos : Random Forest, Naibe Bayes y XGBoost '''\n",
    "    \n",
    "    if Model == \"Random_Forest\":\n",
    "        \n",
    "        Ranf_clf = {'n_estimators': [64, 128, 256, 512, 1024],\n",
    "                    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                    'max_depth': [2, 4, 8, 16, 32, 64, 128],\n",
    "                    'criterion': ['gini', 'entropy']\n",
    "                   }\n",
    "        \n",
    "        estimador_RF = RandomForestClassifier(random_state = 42,\n",
    "                                              n_jobs = multiprocessing.cpu_count()-1)\n",
    "        \n",
    "        RF_CECTI = GridSearchCV(estimator = estimador_RF,\n",
    "                                param_grid = Ranf_clf,\n",
    "                                cv = RepeatedKFold(n_splits = 3, \n",
    "                                                   n_repeats = 1, \n",
    "                                                   random_state = 42),\n",
    "                                scoring = 'accuracy',\n",
    "                                refit = True,\n",
    "                                verbose = 0,\n",
    "                                return_train_score = True)\n",
    "        \n",
    "        CECTI_RF = RF_CECTI.fit(X_train,y_train)\n",
    "        \n",
    "        Best_estimador = CECTI_RF.best_estimator_\n",
    "        \n",
    "        pickle.dump(Best_estimador, open(\"Estimador_RF_QD.pkl\", \"wb\"))\n",
    "        \n",
    "        y_hat = Best_estimador.predict(X = X_test)\n",
    "        \n",
    "        RF_accuracy = metrics.accuracy_score(y_hat, y_test)\n",
    "        \n",
    "        print(\"----------------------------\")\n",
    "        print(\"----------------------------\")\n",
    "        print (\"Random Forest > Accuracy: \", np.round((RF_accuracy*100), 3), '%')\n",
    "        print(\"----------------------------\")\n",
    "        print('Reporte de clasificación: \\n', classification_report(y_test, y_hat))\n",
    "        \n",
    "    elif Model == \"Naibe_Bayes\":\n",
    "        \n",
    "        n_classes = np.unique(y_train)\n",
    "        \n",
    "        params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "                  'fit_prior': [True, False],\n",
    "                  'class_prior': [None, [0.1,]* len(n_classes)]\n",
    "                 }\n",
    "        \n",
    "        Esti_MNB = MultinomialNB()\n",
    "        \n",
    "        MNB_grid = GridSearchCV(Esti_MNB,\n",
    "                                param_grid = params, \n",
    "                                n_jobs = multiprocessing.cpu_count()-1,\n",
    "                                cv = RepeatedKFold(n_splits = 3, n_repeats = 1,\n",
    "                                                   random_state = 42),\n",
    "                                verbose =0 )\n",
    "        \n",
    "        CECTI_MNB = MNB_grid.fit(X_train,y_train)\n",
    "        \n",
    "        Best_estimador = CECTI_MNB.best_estimator_\n",
    "        \n",
    "        pickle.dump(Best_estimador, open(\"Estimador_NB_QD.pkl\", \"wb\"))\n",
    "        \n",
    "        y_hat = Best_estimador.predict(X = X_test)\n",
    "        \n",
    "        NB_accuracy = metrics.accuracy_score(y_hat, y_test)\n",
    "        \n",
    "        print(\"----------------------------\")\n",
    "        print(\"----------------------------\")\n",
    "        print (\"Naibe Bayes > Accuracy: \", np.round((NB_accuracy*100), 3), '%')\n",
    "        print(\"----------------------------\")\n",
    "        print('Reporte de clasificación: \\n', classification_report(y_test, y_hat))\n",
    "    \n",
    "    elif Model == \"XGBoost\":\n",
    "        \n",
    "        xgb_params = {'max_depth':[None, 1, 3, 5, 10, 20, 30],\n",
    "                      'learning_rate':[0.001, 0.01, 0.1],\n",
    "                      'n_estimators': [50, 100, 200]\n",
    "                     }\n",
    "        \n",
    "        Esti_XGB = xgb.XGBClassifier(objective = 'multi:softprob')\n",
    "        \n",
    "        XGB_grid = GridSearchCV(estimator = Esti_XGB,\n",
    "                                param_grid = xgb_params,\n",
    "                                n_jobs = multiprocessing.cpu_count()-1,\n",
    "                                cv = RepeatedKFold(n_splits = 5, \n",
    "                                                   n_repeats = 3, \n",
    "                                                   random_state = 42),\n",
    "                                scoring='accuracy',\n",
    "                                verbose = 0)\n",
    "        \n",
    "        CECTI_XGB = XGB_grid.fit(X_train,y_train)\n",
    "        \n",
    "        Best_estimador = CECTI_XGB.best_estimator_\n",
    "        \n",
    "        pickle.dump(Best_estimador, open(\"Estimador_XGB_QD.pkl\", \"wb\"))\n",
    "        \n",
    "        y_hat = Best_estimador.predict(X = X_test)\n",
    "        \n",
    "        XG_accuracy = metrics.accuracy_score(y_hat, y_test)\n",
    "        \n",
    "        print(\"----------------------------\")\n",
    "        print(\"----------------------------\")\n",
    "        print (\"XGBoost > Accuracy: \", np.round((XG_accuracy*100), 3), '%')\n",
    "        print(\"----------------------------\")\n",
    "        print('Reporte de clasificación: \\n', classification_report(y_test, y_hat))\n",
    "    \n",
    "    return(Best_estimador)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c58be6fd-aaf5-4a36-9044-34ffc05cd718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "----------------------------\n",
      "Random Forest > Accuracy:  97.638 %\n",
      "----------------------------\n",
      "Reporte de clasificación: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     31861\n",
      "           1       0.93      0.99      0.96     12036\n",
      "\n",
      "    accuracy                           0.98     43897\n",
      "   macro avg       0.96      0.98      0.97     43897\n",
      "weighted avg       0.98      0.98      0.98     43897\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=128, max_features=&#x27;auto&#x27;, n_estimators=64,\n",
       "                       n_jobs=7, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=128, max_features=&#x27;auto&#x27;, n_estimators=64,\n",
       "                       n_jobs=7, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=128, max_features='auto', n_estimators=64,\n",
       "                       n_jobs=7, random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aprendizaje_Queja_Denuncia(X_train_N, X_test_N, y_train, y_test, \"Random_Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9ebd8c3-bf94-458d-b5bd-c775a4b66920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import multiprocessing\n",
    "\n",
    "def Aprendizaje_Queja_Denuncia(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Función de modelo de aprendizaje automático que evalúa:\n",
    "    Random Forest, Naive Bayes y XGBoost,\n",
    "    seleccionando automáticamente el mejor modelo.\n",
    "    \"\"\"\n",
    "    # Definir los modelos y sus configuraciones\n",
    "    modelos = {\n",
    "        \"Random_Forest\": {\n",
    "            \"estimator\": RandomForestClassifier(random_state=42, n_jobs=multiprocessing.cpu_count() - 1),\n",
    "            \"params\": {\n",
    "                'n_estimators': [64, 128, 256, 512, 1024],\n",
    "                'max_features': ['sqrt', 'log2'],\n",
    "                'max_depth': [2, 4, 8, 16, 32, 64, 128],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        },\n",
    "        \"Naive_Bayes\": {\n",
    "            \"estimator\": MultinomialNB(),\n",
    "            \"params\": {\n",
    "                'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "                'fit_prior': [True, False],\n",
    "                'class_prior': [None, [0.1] * len(np.unique(y_train))]\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"estimator\": XGBClassifier(objective='multi:softprob'),\n",
    "            \"params\": {\n",
    "                'max_depth': [None, 1, 3, 5, 10, 20, 30],\n",
    "                'learning_rate': [0.001, 0.01, 0.1],\n",
    "                'n_estimators': [50, 100, 200]\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Variables para almacenar el mejor modelo\n",
    "    mejor_modelo = None\n",
    "    mejor_accuracy = 0\n",
    "    mejor_nombre = \"\"\n",
    "    \n",
    "    # Iterar sobre los modelos\n",
    "    for nombre, config in modelos.items():\n",
    "        print(f\"Entrenando modelo: {nombre}\")\n",
    "        \n",
    "        # Configurar GridSearchCV\n",
    "        grid = GridSearchCV(\n",
    "            estimator=config[\"estimator\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            cv=config[\"cv\"],\n",
    "            scoring='accuracy',\n",
    "            n_jobs=multiprocessing.cpu_count() - 1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Entrenar el modelo\n",
    "        grid.fit(X_train, y_train)\n",
    "        mejor_estimador = grid.best_estimator_\n",
    "        \n",
    "        # Evaluar el modelo\n",
    "        y_pred = mejor_estimador.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{nombre} > Accuracy: {np.round(accuracy * 100, 3)}%\")\n",
    "        print('Reporte de clasificación:\\n', classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Actualizar el mejor modelo si tiene mejor rendimiento\n",
    "        if accuracy > mejor_accuracy:\n",
    "            mejor_accuracy = accuracy\n",
    "            mejor_modelo = mejor_estimador\n",
    "            mejor_nombre = nombre\n",
    "    \n",
    "    # Guardar el mejor modelo\n",
    "    print(f\"\\nEl mejor modelo es: {mejor_nombre} con una precisión de {np.round(mejor_accuracy * 100, 3)}%\")\n",
    "    pickle.dump(mejor_modelo, open(f\"Mejor_Modelo_{mejor_nombre}.pkl\", \"wb\"))\n",
    "    \n",
    "    return mejor_modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c256adea-d1f0-480b-a177-064d41b150a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import multiprocessing\n",
    "\n",
    "def Aprendizaje_Queja_Denuncia(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Función de modelo de aprendizaje automático que evalúa:\n",
    "    Random Forest, Naive Bayes y XGBoost,\n",
    "    seleccionando automáticamente el mejor modelo.\n",
    "    \"\"\"\n",
    "    # Verificar que las etiquetas están correctamente codificadas\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    # Determinar el número de clases\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    print(f\"Número de clases: {n_classes}\")\n",
    "    \n",
    "    # Definir los modelos y sus configuraciones\n",
    "    modelos = {\n",
    "        \"Random_Forest\": {\n",
    "            \"estimator\": RandomForestClassifier(random_state=42, n_jobs=multiprocessing.cpu_count() - 1),\n",
    "            \"params\": {\n",
    "                'n_estimators': [64, 128, 256, 512, 1024],\n",
    "                'max_features': ['sqrt', 'log2'],  # 'auto' reemplazado por 'sqrt'\n",
    "                'max_depth': [2, 4, 8, 16, 32, 64, 128],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        },\n",
    "        \"Naive_Bayes\": {\n",
    "            \"estimator\": MultinomialNB(),\n",
    "            \"params\": {\n",
    "                'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "                'fit_prior': [True, False],\n",
    "                'class_prior': [None, [0.1] * n_classes]\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"estimator\": XGBClassifier(objective='multi:softprob', num_class=n_classes),\n",
    "            \"params\": {\n",
    "                'max_depth': [1, 3, 5, 10, 20],\n",
    "                'learning_rate': [0.001, 0.01, 0.1],\n",
    "                'n_estimators': [50, 100, 200]\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Variables para almacenar el mejor modelo\n",
    "    mejor_modelo = None\n",
    "    mejor_accuracy = 0\n",
    "    mejor_nombre = \"\"\n",
    "    \n",
    "    # Iterar sobre los modelos\n",
    "    for nombre, config in modelos.items():\n",
    "        print(f\"Entrenando modelo: {nombre}\")\n",
    "        \n",
    "        # Configurar GridSearchCV con error_score='raise'\n",
    "        grid = GridSearchCV(\n",
    "            estimator=config[\"estimator\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            cv=config[\"cv\"],\n",
    "            scoring='accuracy',\n",
    "            n_jobs=multiprocessing.cpu_count() - 1,\n",
    "            verbose=0,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        \n",
    "        # Entrenar el modelo\n",
    "        grid.fit(X_train, y_train)\n",
    "        mejor_estimador = grid.best_estimator_\n",
    "        \n",
    "        # Evaluar el modelo\n",
    "        y_pred = mejor_estimador.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{nombre} > Accuracy: {np.round(accuracy * 100, 3)}%\")\n",
    "        print('Reporte de clasificación:\\n', classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Actualizar el mejor modelo si tiene mejor rendimiento\n",
    "        if accuracy > mejor_accuracy:\n",
    "            mejor_accuracy = accuracy\n",
    "            mejor_modelo = mejor_estimador\n",
    "            mejor_nombre = nombre\n",
    "    \n",
    "    # Guardar el mejor modelo\n",
    "    print(f\"\\nEl mejor modelo es: {mejor_nombre} con una precisión de {np.round(mejor_accuracy * 100, 3)}%\")\n",
    "    pickle.dump(mejor_modelo, open(f\"Mejor_Modelo_{mejor_nombre}.pkl\", \"wb\"))\n",
    "    \n",
    "    return mejor_modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fc63eab-b723-46dc-96af-feb956b293d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import multiprocessing\n",
    "\n",
    "def Aprendizaje_Queja_Denuncia(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Función de modelo de aprendizaje automático que evalúa:\n",
    "    Random Forest, Naive Bayes y XGBoost,\n",
    "    seleccionando automáticamente el mejor modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verificar y ajustar el formato de las etiquetas\n",
    "    if len(y_train.shape) > 1:  # Etiquetas multilabel-indicator\n",
    "        print(\"Las etiquetas están en formato multilabel. Convirtiendo a unidimensional.\")\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "    else:\n",
    "        print(\"Etiquetas unidimensionales detectadas. Aplicando codificación si es necesario.\")\n",
    "        le = LabelEncoder()\n",
    "        y_train = le.fit_transform(y_train)\n",
    "        y_test = le.transform(y_test)\n",
    "    \n",
    "    # Determinar el número de clases\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    print(f\"Número de clases: {n_classes}\")\n",
    "    \n",
    "    # Definir los modelos y sus configuraciones\n",
    "    modelos = {\n",
    "        \"Random_Forest\": {\n",
    "            \"estimator\": RandomForestClassifier(random_state=42, n_jobs=multiprocessing.cpu_count() - 1),\n",
    "            \"params\": {\n",
    "                'n_estimators': [64, 128, 256, 512, 1024],\n",
    "                'max_features': ['sqrt', 'log2'],  # 'auto' reemplazado por 'sqrt'\n",
    "                'max_depth': [2, 4, 8, 16, 32, 64, 128],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        },\n",
    "        \"Naive_Bayes\": {\n",
    "            \"estimator\": MultinomialNB(),\n",
    "            \"params\": {\n",
    "                'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "                'fit_prior': [True, False],\n",
    "                'class_prior': [None, [0.1] * n_classes]\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"estimator\": XGBClassifier(objective='multi:softprob' if n_classes > 2 else 'binary:logistic', \n",
    "                                       num_class=n_classes if n_classes > 2 else None),\n",
    "            \"params\": {\n",
    "                'max_depth': [1, 3, 5, 10, 20],\n",
    "                'learning_rate': [0.001, 0.01, 0.1],\n",
    "                'n_estimators': [50, 100, 200]\n",
    "            },\n",
    "            \"cv\": RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Variables para almacenar el mejor modelo\n",
    "    mejor_modelo = None\n",
    "    mejor_accuracy = 0\n",
    "    mejor_nombre = \"\"\n",
    "    \n",
    "    # Iterar sobre los modelos\n",
    "    for nombre, config in modelos.items():\n",
    "        print(f\"\\nEntrenando modelo: {nombre}\")\n",
    "        \n",
    "        # Configurar GridSearchCV con error_score='raise'\n",
    "        grid = GridSearchCV(\n",
    "            estimator=config[\"estimator\"],\n",
    "            param_grid=config[\"params\"],\n",
    "            cv=config[\"cv\"],\n",
    "            scoring='accuracy',\n",
    "            n_jobs=multiprocessing.cpu_count() - 1,\n",
    "            verbose=0,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Entrenar el modelo\n",
    "            grid.fit(X_train, y_train)\n",
    "            mejor_estimador = grid.best_estimator_\n",
    "            \n",
    "            # Evaluar el modelo\n",
    "            y_pred = mejor_estimador.predict(X_test)\n",
    "            accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            print(f\"{nombre} > Accuracy: {np.round(accuracy * 100, 3)}%\")\n",
    "            print('Reporte de clasificación:\\n', classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Actualizar el mejor modelo si tiene mejor rendimiento\n",
    "            if accuracy > mejor_accuracy:\n",
    "                mejor_accuracy = accuracy\n",
    "                mejor_modelo = mejor_estimador\n",
    "                mejor_nombre = nombre\n",
    "        except Exception as e:\n",
    "            print(f\"Error entrenando el modelo {nombre}: {e}\")\n",
    "    \n",
    "    # Guardar el mejor modelo\n",
    "    if mejor_modelo is not None:\n",
    "        print(f\"\\nEl mejor modelo es: {mejor_nombre} con una precisión de {np.round(mejor_accuracy * 100, 3)}%\")\n",
    "        pickle.dump(mejor_modelo, open(f\"Mejor_Modelo_{mejor_nombre}.pkl\", \"wb\"))\n",
    "    else:\n",
    "        print(\"No se encontró un modelo válido.\")\n",
    "    \n",
    "    return mejor_modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1ffdf-0339-4b12-a213-ea72c66a696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas unidimensionales detectadas. Aplicando codificación si es necesario.\n",
      "Número de clases: 2\n",
      "\n",
      "Entrenando modelo: Random_Forest\n",
      "Random_Forest > Accuracy: 97.638%\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     31861\n",
      "           1       0.93      0.99      0.96     12036\n",
      "\n",
      "    accuracy                           0.98     43897\n",
      "   macro avg       0.96      0.98      0.97     43897\n",
      "weighted avg       0.98      0.98      0.98     43897\n",
      "\n",
      "\n",
      "Entrenando modelo: Naive_Bayes\n",
      "Naive_Bayes > Accuracy: 96.07%\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     31861\n",
      "           1       0.91      0.95      0.93     12036\n",
      "\n",
      "    accuracy                           0.96     43897\n",
      "   macro avg       0.95      0.96      0.95     43897\n",
      "weighted avg       0.96      0.96      0.96     43897\n",
      "\n",
      "\n",
      "Entrenando modelo: XGBoost\n"
     ]
    }
   ],
   "source": [
    "mejor_modelo = Aprendizaje_Queja_Denuncia(X_train_N, X_test_N, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c800b30-57ed-4a4a-af2a-b76b8166537f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
